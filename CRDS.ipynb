{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43bc1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc78a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_crds(datasets_ini, alpha=1, beta_up=1.3, beta_down=0.3, gamma_up=1.6, gamma_down=0.6, T_g=120, T_n=5000):\n",
    "    # Extract reactants, reagents, and reactions from the datasets to find max values\n",
    "    datasets = copy.deepcopy(datasets_ini)\n",
    "    reactants = [d[0] for d in datasets]\n",
    "    reagents = [d[1] for d in datasets]\n",
    "    reactions = [d[2] for d in datasets]\n",
    "    \n",
    "    # Get the max values\n",
    "    max_reactants = max(reactants)\n",
    "    max_reagents = max(reagents)\n",
    "    max_reactions = max(reactions)\n",
    "    \n",
    "    # Calculate the score for each dataset and insert it into the respective sublist\n",
    "    for dataset in datasets:\n",
    "        R_t, R_g, R_n = dataset[0], dataset[1], dataset[2]\n",
    "        \n",
    "        # R_t contribution\n",
    "        R_t_contrib = (R_t / max_reactants) ** alpha\n",
    "        \n",
    "        # R_g contribution with modified weighting\n",
    "        if R_g <= T_g:\n",
    "            R_g_contrib = (R_g / max_reagents) ** beta_up\n",
    "        else:\n",
    "            R_g_contrib = (T_g / max_reagents) ** beta_up * (R_g / T_g) ** beta_down\n",
    "        \n",
    "        # R_n contribution with modified weighting for reactions\n",
    "        if R_n <= T_n:\n",
    "            R_n_contrib = (R_n / max_reactions) ** gamma_up\n",
    "        else:\n",
    "            R_n_contrib = (T_n / max_reactions) ** gamma_up * (R_n / T_n) ** gamma_down\n",
    "        \n",
    "        # Total score\n",
    "        score = R_t_contrib * R_g_contrib * R_n_contrib\n",
    "        \n",
    "        # Insert the score into the dataset\n",
    "        dataset.insert(3, score)\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "def summarize_sources_with_combined(df):\n",
    "    # List to hold summary information for each source\n",
    "    summary_list = []\n",
    "    \n",
    "    # Grouping the DataFrame by 'Source'\n",
    "    grouped = df.groupby('Source')\n",
    "    \n",
    "    # Iterating over each group\n",
    "    for source, group in grouped:\n",
    "        # Number of unique pairs of 'Aryl Halide SMILES', 'Amine SMILES'\n",
    "        unique_pair_count = group[['Aryl Halide SMILES', 'Amine SMILES']].drop_duplicates().shape[0]\n",
    "        \n",
    "        # Number of unique combinations of 'Catalyst SMILES', 'Solvent SMILES', 'Base SMILES'\n",
    "        unique_combinations_count = group[['Catalyst SMILES', 'Solvent SMILES', 'Base SMILES']].drop_duplicates().shape[0]\n",
    "        \n",
    "        # Total number of rows for the current source\n",
    "        total_rows_count = group.shape[0]\n",
    "        \n",
    "        # Append the summary information as a list\n",
    "        summary_list.append([unique_pair_count, unique_combinations_count, total_rows_count, source])\n",
    "\n",
    "    # DataFrame excluding \"JNJ HTE 2024\"\n",
    "    df_excluding_jnj = df[df['Source'] != \"JNJ HTE 2024\"]\n",
    "    \n",
    "    # Summary for all sources combined except \"JNJ HTE 2024\"\n",
    "    unique_pairs_excl_jnj = df_excluding_jnj[['Aryl Halide SMILES', 'Amine SMILES']].drop_duplicates().shape[0]\n",
    "    unique_combinations_excl_jnj = df_excluding_jnj[['Catalyst SMILES', 'Solvent SMILES', 'Base SMILES']].drop_duplicates().shape[0]\n",
    "    total_rows_excl_jnj = df_excluding_jnj.shape[0]\n",
    "    combined_excl_jnj_summary = [unique_pairs_excl_jnj, unique_combinations_excl_jnj, total_rows_excl_jnj, \"All except JNJ HTE 2024\"]\n",
    "    \n",
    "    # Summary for all sources combined\n",
    "    unique_pairs_all = df[['Aryl Halide SMILES', 'Amine SMILES']].drop_duplicates().shape[0]\n",
    "    unique_combinations_all = df[['Catalyst SMILES', 'Solvent SMILES', 'Base SMILES']].drop_duplicates().shape[0]\n",
    "    total_rows_all = df.shape[0]\n",
    "    combined_all_summary = [unique_pairs_all, unique_combinations_all, total_rows_all, \"All sources\"]\n",
    "\n",
    "    # Add the combined summaries to the summary list\n",
    "    summary_list.append(combined_excl_jnj_summary)\n",
    "    summary_list.append(combined_all_summary)\n",
    "\n",
    "    return summary_list\n",
    "\n",
    "def calculate_correlations(dataframe, reference_column, columns_to_compare):\n",
    "    \"\"\"\n",
    "    Calculate Pearson and Spearman correlations between a reference column \n",
    "    and a list of other columns in a dataframe.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The dataframe containing the data.\n",
    "        reference_column (str): The column name for the reference column.\n",
    "        columns_to_compare (list of str): A list of column names to compare against the reference column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe containing Pearson and Spearman correlations for each column in the list.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for column in columns_to_compare:\n",
    "        if column != reference_column:\n",
    "            # Calculate Pearson and Spearman correlations\n",
    "            pearson_corr, _ = pearsonr(dataframe[reference_column], dataframe[column])\n",
    "            spearman_corr, _ = spearmanr(dataframe[reference_column], dataframe[column])\n",
    "            results.append({\"Column\": column, \"Pearson Correlation\": pearson_corr, \"Spearman Correlation\": spearman_corr})\n",
    "    \n",
    "    # Convert results to a dataframe\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "def load_dataset_summary(csv_file):\n",
    "    \"\"\"\n",
    "    Reads a dataset_summary.csv file and returns a list of lists\n",
    "    of the form: [train_samples, validation_samples, test_samples, dataset_name].\n",
    "    \"\"\"\n",
    "    datasets = []\n",
    "    \n",
    "    with open(csv_file, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        header = next(reader)  # Skip header row\n",
    "        \n",
    "        for row in reader:\n",
    "            # Convert numeric values from strings to integers\n",
    "            train = int(row[0])\n",
    "            validation = int(row[1])\n",
    "            test = int(row[2])\n",
    "            name = row[3]\n",
    "            \n",
    "            datasets.append([train, validation, test, name])\n",
    "    \n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc860948",
   "metadata": {},
   "source": [
    "### Correlation: CRDS vs OOD performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9414dcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Column  Pearson Correlation  Spearman Correlation\n",
      "0            ROC AUC Avg             0.789956              0.452381\n",
      "1  Balanced Accuracy Avg             0.770371              0.428571\n",
      "2           F1 Score Avg             0.308120              0.309524\n",
      "3            AU-PR-C Avg             0.170448              0.285714\n"
     ]
    }
   ],
   "source": [
    "dataset_summary = load_dataset_summary(\"data/dataset_summary.csv\")\n",
    "\n",
    "datasets_w_scores = calculate_crds(copy.deepcopy(dataset_summary), alpha=1, beta_up=0.2, beta_down=0.1, gamma_up=0.9, gamma_down=0.2, T_g=4000, T_n=5000)\n",
    "\n",
    "best_performance = pd.read_csv(\"results/Data_Source_best.csv\", index_col = 0)\n",
    "\n",
    "dic = {\"Train Data\":[], \"CRDS\": []}\n",
    "for scores in datasets_w_scores:\n",
    "    dic[\"Train Data\"].append(scores[4])\n",
    "    dic[\"CRDS\"].append(scores[3])\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "final = best_performance.merge(df, on = [\"Train Data\"])\n",
    "\n",
    "correlations_df = calculate_correlations(final, \"CRDS\", ['ROC AUC Avg', 'Balanced Accuracy Avg', 'F1 Score Avg', 'AU-PR-C Avg'])\n",
    "print(correlations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee567121",
   "metadata": {},
   "source": [
    "### Correlation: Simplified CRDS vs OOD performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "761156c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Column  Pearson Correlation  Spearman Correlation\n",
      "0            ROC AUC Avg             0.534217              0.261905\n",
      "1  Balanced Accuracy Avg             0.558231              0.214286\n",
      "2           F1 Score Avg             0.263111              0.428571\n",
      "3            AU-PR-C Avg             0.381183              0.404762\n"
     ]
    }
   ],
   "source": [
    "dataset_summary = load_dataset_summary(\"data/dataset_summary.csv\")\n",
    "\n",
    "datasets_w_scores = calculate_crds(copy.deepcopy(dataset_summary), alpha=1, beta_up=1, beta_down=1, gamma_up=1.0, gamma_down=1, T_g=4000000, T_n=500000)\n",
    "\n",
    "best_performance = pd.read_csv(\"results/Data_Source_best.csv\", index_col = 0)\n",
    "\n",
    "dic = {\"Train Data\":[], \"CRDS\": []}\n",
    "for scores in datasets_w_scores:\n",
    "    dic[\"Train Data\"].append(scores[4])\n",
    "    dic[\"CRDS\"].append(scores[3])\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "final = best_performance.merge(df, on = [\"Train Data\"])\n",
    "\n",
    "correlations_df = calculate_correlations(final, \"CRDS\", ['ROC AUC Avg', 'Balanced Accuracy Avg', 'F1 Score Avg', 'AU-PR-C Avg'])\n",
    "print(correlations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e003c05c",
   "metadata": {},
   "source": [
    "### Correlation: Dataset Size vs OOD performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4d819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Column  Pearson Correlation  Spearman Correlation\n",
      "0            ROC AUC Avg             0.603495              0.476190\n",
      "1  Balanced Accuracy Avg             0.540669              0.404762\n",
      "2           F1 Score Avg             0.286920             -0.214286\n",
      "3            AU-PR-C Avg             0.062482             -0.309524\n"
     ]
    }
   ],
   "source": [
    "best_performance = pd.read_csv(\"results/Data_Source_best.csv\")\n",
    "\n",
    "dic = {\"Train Data\":['Chem.S.23', 'Sci.15', 'Chem.S.16', 'Sci.18', 'Nat.C.24', \"JACS.25\",\n",
    "                     'JnJ25', 'Sci.23'],\n",
    "        \"dataset_size\":[750, 768, 144, 4312, 2632, 4204, 11328, 3359]}\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "final = best_performance.merge(df, on = [\"Train Data\"])\n",
    "correlations_df = calculate_correlations(final, \"dataset_size\", ['ROC AUC Avg', 'Balanced Accuracy Avg', 'F1 Score Avg', 'AU-PR-C Avg'])\n",
    "print(correlations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5531651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-bee_exp]",
   "language": "python",
   "name": "conda-env-.conda-bee_exp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
